In this section, we present and analyze the results obtained from the experiments conducted on the methods introduced in the previous chapters. For each macro-category, two algorithmic approaches were implemented. The analysis is divided into two phases: first, the main parameters are fine-tuned (when applicable), and then the best-performing configurations within each category are compared.

\section{Methodology}

Each group of algorithms is analyzed independently, following a consistent methodology. Three main parameters are considered throughout the experiments:
\begin{itemize}
    \item \textbf{Number of nodes:} This varies depending on the method's nature (e.g., fewer nodes for exact methods, more for heuristics and metaheuristics).
    \item \textbf{Time limit:} A fixed time budget is set for all experiments to ensure comparability.
    \item \textbf{Number of runs:} Each configuration is tested on 20 randomly generated instances to ensure statistical significance.
\end{itemize}

Specifically, the following settings were adopted:
\begin{itemize}
    \item \textbf{Heuristics:} 1000-node instances, 120-second time limit.
    \item \textbf{Metaheuristics:} 1000-node instances, 120-second time limit.
    \item \textbf{Exact methods:} 200-node instances, 120-second time limit.
\end{itemize}

Each test was repeated on 20 instances, initialized with distinct random seeds. To enable rigorous comparisons, we rely on \textbf{performance profiles}, a graphical benchmarking tool that allows us to assess and visualize the relative efficiency of different algorithms across a set of problem instances~\cite{dolan2002performance}.

\subsection{Instance Generation}

The TSP instances used in our experiments are generated randomly. Each instance consists of a set of points placed on a 2D grid $[0, 10\,000] \times [0, 10\,000]$, with coordinates sampled from an independent and identically distributed model. The cost matrix for each instance is computed using the Euclidean distance between points, optionally rounded according to the \emph{ATT} formula from TSPLIB~\cite{reinelt1995tsplib}.

\subsection{Experimental Setup}

The exact and matheuristic methods were solved using \textbf{IBM ILOG CPLEX 22.1.2}~\cite{cplex2023}, interfaced via its C API. Greedy and heuristic algorithms were implemented in C for performance reasons, while Python was used for result visualization and data processing.

To ensure comparability, all algorithms within the same category were executed sequentially on the same hardware. However, different classes of methods were executed on different machines, as detailed below:

\begin{center}
\begin{tabular}{ c | c | c }
  \textbf{Processor} & \textbf{RAM} & \textbf{Algorithms Executed} \\
  \hline
  Intel Core i7-10510U & 16 GB & Exact, Matheuristic \\
  Intel Core i5-8265U  & 16 GB & Greedy, Heuristic \\
\end{tabular}
\end{center}

\subsection{Performance Profiles}

To compare algorithm performance across a common set of instances, we used performance profiles. These were generated using a Python script developed by Professor Domenico Salvagnin. The script processes a CSV file containing the results of each algorithm on each instance and compares the performance to the best value achieved on that instance.

This approach enables the construction of plots that show, for each algorithm, the proportion of instances for which its performance is within a given factor of the best. For heuristic and metaheuristic methods, the comparison is based on the objective value of the best solution found; for exact methods, it is based on the time required to find the optimal solution.

\section{Parameters tuning}

\subsection{Nearest Neighbor - Greedy}
\label{ssec:nn-tuning}

In the case of Nearest Neighbor method we don't have any parameters to tune, but we can analyze if the Two-Opt step is beneficial or not. It is intuitive from the definion presented in section \ref{sec:2opt} that the 2-opt step is always beneficial, as it can only improve the quality of the tour. For completeness, we report the performance profiles of the Nearest Neighbor method with and without the 2-opt step in Figure~\ref{fig:nn-profiles}.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{greedy_profiles.pdf}
  \caption{Performance profiles for the Greedy method.}
  \label{fig:nn-profiles}
\end{figure}

\subsection{Tabu Search}
\label{ssec:tabu-tuning}
As discussed in Section~\ref{sec:tabu}, Tabu Search relies on a short-term memory of forbidden moves, whose size is governed by the base tenure \(T\).  In many works one selects a single ratio \(\alpha\) and sets \(T=\frac{N_{\mathrm{nodes}}}{\alpha}\), but this hides the fact that the method can be tuned more flexibly by independently controlling the dynamic bounds \(T_{\min}\) and \(T_{\max}\).

In our implementation we therefore allow the user to specify all parameters directly, allowing also for setting the cutoff for forced diversification, \(N_{\mathrm{ni}}\). Conceptually, however, it is still suggested to leverage the ratio \(\alpha\) to derive the base tenure \(T\).

Table~\ref{tab:tabu-configs} reports the eight configurations where we tried to span as many different search behaviors as possible.

\begin{table}[H]
  \centering
  \caption{Tabu search configurations}
  \label{tab:tabu-configs}
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{|c|c|c|c|l|}
    \hline
    \textbf{$T$} & \textbf{$T_{\min}$} & \textbf{$T_{\max}$} & \textbf{$N_{\mathrm{ni}}$} & \textbf{Description} \\ 
    \hline
    227 & 10 & 227 & 500 & Good balance, but no expansion beyond the initial tenure. \\
    250 & 10  & 375  & 500  & Moderate diversification via expanded max tenure. \\ 
    208 & 5   & 416  & 1000 & Broad tenure span allows prolonged exploration before reset. \\ 
    278 & 20  & 278  & 250  & Fixed high tenure intensifies local moves with quick shake-up. \\ 
    167 & 10  & 167  & 500  & Small tenure forces rapid neighborhood changes. \\ 
    333 & 10  & 500  & 500  & Max tenure scaled to problem size supports deeper history. \\ 
    100 & 5   & 500  & 200  & Very short base tenure and low cutoff for intense shaking. \\ 
    400 & 50  & 400  & 2000 & Large tenure and high cutoff delay diversification for global search. \\ 
    \hline
  \end{tabular}%
  }
\end{table}

Results highlight that configurations with a large base tenure and a wide dynamic span tend to converge more quickly to high-quality incumbents. In particular:
\begin{itemize}
  \item \emph{High base tenure}: retaining a long short-term memory before forcing diversification produces the best overall performance, by exploiting promising regions.
  \item \emph{Wide dynamic window}: allowing the tabu tenure to expand and contract over a large interval helps escape local optima when progress stalls.
  \item \emph{Medium settings}: a moderate base tenure with a moderately sized dynamic range provides a reasonable trade-off between intensification and diversification, but does not match the extremes.
  \item \emph{Small or rigid tenure}: very short or fixed tabu lists lead to slower discovery of good solutions and a greater risk of stagnation.
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{tabu_profiles.pdf}
  \caption{Performance profiles for the Tabu Search configurations.}
  \label{fig:tabu-profiles}
\end{figure}

\subsection{Varable Neighborhood Search}
\label{ssec:vns-tuning}

To find the best configuration for the VNS algorithm, we focused on the parameters that control the number of 3-opt “kicks” applied per iteration. We let the user specify a fixed number of kicks \(J\) or an adaptive scheme that draws a number of kicks uniformly from a range \([k_{\min},k_{\max}]\), scaled by a learning rate \(\lambda\). Table~\ref{tab:vns-configs} summarizes the settings we evaluated:

\begin{table}[H]
  \centering
  \caption{VNS configurations}
  \label{tab:vns-configs}
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{|c|c|c|c|c|l|}
    \hline
    \textbf{ID} & \(\boldsymbol{k_{\min}}\) & \(\boldsymbol{k_{\max}}\) & \(\boldsymbol{\lambda}\) & \(\boldsymbol{J}\) & \textbf{Description} \\ 
    \hline
    1 & 2   & 4   & 1.00 & -  & Balanced adaptive kicks. \\ 
    2 & 1   & 5   & 1.00 & -  & Wide range for broader exploration. \\ 
    3 & 2   & 6   & 1.00 & -  & Extended range for more diversification. \\ 
    4 & 1   & 10  & 1.00 & -  & Very wide span, high diversification. \\ 
    5 & 2   & 4   & 0.50 & -  & Conservative kicks (half learning rate). \\ 
    8 & 2   & 4   & 2.00 & -  & Aggressive kicks (double learning rate). \\ 
    6 & -   & -   & -    & 3  & Fixed few kicks per iteration. \\ 
    7 & -   & -   & -    & 10 & Fixed many kicks, conservative scale. \\ 
    \hline
  \end{tabular}%
  }
\end{table}

Results presented in Figure \ref{fig:vns-profiles} suggest that a fixed number of kicks per iterations is more effective than adaptive schemes. In particular, the more kicks are applied the better the results, with the with the configuration applying 10 kicks outperforming all others. Anyways, the adaptive schemes still perform reasonably well, especially when the range of kicks is wide enough to allow for sufficient exploration.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{vns_profiles.pdf}
  \caption{Performance profiles for the VNS configurations.}
  \label{fig:vns-profiles}
\end{figure}

\section{Methods comparison}

\subsection{Best Heuristic - Full time limit}

After tuning the parameters of the Tabu Search and VNS algorithms we now compare their performance to determine the best heuristic for solving the TSP. We assume that the experiments performed during the parameters tuning phase cover a wide range of search behaviors and thus considering the four best configurations of each method is sufficient to draw conclusions on the overall performance of the two methods.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{best_heuristic_profiles.pdf}
  \caption{Performance profiles to compare VNS and Tabu Search.}
  \label{fig:best-heuristic-profiles}
\end{figure}

Looking at Figure \ref{fig:best-heuristic-profiles} there is no doubt on the superiority of the Tabu Search algorithm, the method configurations used in the comparison cover different search behaviours and all outperform the VNS configurations.

One more interesting comparison is to check how an approach as simple as the Nearest Neighbor with 2-opt compares to the best heuristic. The results are shown in Figure \ref{fig:nn-vs-best-heuristic} and clearly show that the complicated and time-demanding search performed by Tabu is justifide by the quality of the solutions found, which is significantly better.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{nn_tabu_profiles.pdf}
  \caption{Tabu Search compared to Nearest Neighbor with 2-opt.}
  \label{fig:nn-vs-best-heuristic}
\end{figure}

\subsection{Best Heuristic - Short Time Budget}
\label{ssec:short-heuristic}
All CPLEX-based exact methods are initialized with a heuristic solution obtained by allocating 10\% of the total time limit to the heuristic. To identify the most effective warm-start configuration, we therefore evaluate our top Tabu Search settings using a reduced time budget of 12 seconds. The best-performing configuration from this experiment will be used to warm-start the exact methods, which are compared in the next chapter. Since the instances of exact methods will be smaller, we are now searching for percentages of the number of nodes to set the tenure size, rather than absolute values.

From Figure \ref{fig:fast-heuristic} we can see that the best-performing configuration now is the one with a tenure size of around 28\% of the number of nodes and a minimum size of 2\%. This is a sigificant difference from the previous experiments, where the bigger tenure size was the best, this is likely due to the fact that with a short time limit the algorithm needs to explore more and thus a smaller tenure size allows for more diversification.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{fast_heuristic_profiles.pdf}
  \caption{Tabu Search performance profiles under a 12-second time limit.}
  \label{fig:fast-heuristic}
\end{figure}

\subsection{Best Exact Method}

This section compares the Exact Methods introduced in Chapter \ref{chap:exact-methods}. While these methods do not involve any fine-tuning, we still explore variations in their configurations to evaluate performance differences. Specifically, we examine three different approaches for initializing the solver:

\begin{itemize}
\item \textbf{No Warm Start}: In this baseline approach, CPLEX performs the optimization from scratch without any preprocessing or initial solution.
\item \textbf{Heuristic Warm Start}: As discussed in Section \ref{ssec:short-heuristic}, we identified the best configuration for a time-limited heuristic. The solution obtained from this heuristic is used as the starting point for the exact solver.
\item \textbf{Two-Opt Warm Start}: We observed that a simple greedy solution refined with the two-opt technique yields a reasonable solution in under one second. Although typically worse than the heuristic solution, we aim to test whether this quick-start approach can help the exact method reach optimality faster.
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{exact_profiles.pdf}
  \caption{Exact Methods performance profiles.}
  \label{fig:exact}
\end{figure}

Figure~\ref{fig:exact} shows the performance profiles of the exact solver under different initialization strategies. The standard \textbf{Branch-and-Cut} method performs best overall, solving most instances quickly and reliably. Its version initialized with a \textbf{Two-Opt} solution performs comparably, and slightly better on some instances, suggesting that this quick-start approach can help without adding overhead.

Interestingly, \textbf{Two-Opt} also provides a noticeable improvement when combined with \textbf{Benders}, making it significantly more effective than the standard Benders configuration. In contrast, warm starts using the \textbf{Tabu} heuristic degrade performance, likely because they consume more time while providing solutions that are not sufficiently better to justify the delay.

Overall, standard configurations, especially Branch-and-Cut, are highly effective. Lightweight warm starts like Two-Opt may offer modest improvements, particularly for Benders, while heavier ones like Tabu are counterproductive.
